{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://api.dailysmarty.com/posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r.__dict__.__contains__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Response.json of <Response [200]>>\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(r.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__',\n",
      " '__class__',\n",
      " '__delattr__',\n",
      " '__dir__',\n",
      " '__doc__',\n",
      " '__eq__',\n",
      " '__format__',\n",
      " '__func__',\n",
      " '__ge__',\n",
      " '__get__',\n",
      " '__getattribute__',\n",
      " '__gt__',\n",
      " '__hash__',\n",
      " '__init__',\n",
      " '__init_subclass__',\n",
      " '__le__',\n",
      " '__lt__',\n",
      " '__ne__',\n",
      " '__new__',\n",
      " '__reduce__',\n",
      " '__reduce_ex__',\n",
      " '__repr__',\n",
      " '__self__',\n",
      " '__setattr__',\n",
      " '__sizeof__',\n",
      " '__str__',\n",
      " '__subclasshook__']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dir(r.json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'posts': [{'id': 6822,\n",
       "   'title': 'How to Rename a Column in Ruby on Rails',\n",
       "   'content': '<p>The Ruby on Rails framework has some helpful shorthand methods for when you want to change the structure of your database. If you want to rename a column, you can create a migration with the terminal command:</p>\\r\\n\\r\\n<p>rails g migration change_some_name</p>\\r\\n\\r\\n<p>And then the code in the migration file should look something like this:</p>\\r\\n\\r\\n<p>class ChangeSomeName &lt; ActiveRecord::Migration[6.0]<br />\\r\\n&nbsp; def change<br />\\r\\n&nbsp; &nbsp; rename_column :table_name, :old_name, :new_name<br />\\r\\n&nbsp; end<br />\\r\\nend</p>\\r\\n\\r\\n<p>After you run: rails db:migrate, the new name will be updated in the database. A few things to keep in mind:</p>\\r\\n\\r\\n<ul>\\r\\n\\t<li>Make sure to update any/all mentions of the old name in the: strong params, serializers, seed files, show templates, etc.</li>\\r\\n\\t<li>Ensure that the table name you&#39;re using matches the table name as it appears in the db/schema.rb file</li>\\r\\n</ul>\\r\\n\\r\\n<p>For more information on rails migrations, the guide below is very helpful.</p>\\r\\n',\n",
       "   'created_at': '2020-07-29T01:34:31.773Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/how-to-rename-a-column-in-ruby-on-rails',\n",
       "   'associated_topics': ['Rails Migrations', 'Databases', 'Ruby on Rails'],\n",
       "   'post_links': [{'link_url': 'https://edgeguides.rubyonrails.org/active_record_migrations.html'}]},\n",
       "  {'id': 6591,\n",
       "   'title': 'Important Difference between Machine Learning vs Artificial Intelligence vs Deep Learning',\n",
       "   'content': '<p><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Artificial Intelligence is the technique of developing machines that imitate human behaviour. It provides objects, machines, and systems the ability to simulate human behaviour.&nbsp;</b></p>\\r\\n\\r\\n<p><meta charset=\"utf-8\" /></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Think of this way - Artificial Intelligence(AI) systems are machines that think and act as humans do. They have an intelligent brain, just like humans do.</b></p>\\r\\n\\r\\n<p><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">It is useful to your organization in ways you can&rsquo;t even imagine - an accurate visual perception of data, speech recognition, extracting insights from data, translation of documents and languages, and much more.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Machine Learning is the building blocks behind Artificial Intelligence systems. You might have read somewhere about AI and ML and probably gotten confused.&nbsp;</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">You may also think that <a href=\"https://www.botreetechnologies.com/artificial-intelligence-solutions\" target=\"_blank\">AI is a subset of Machine Learning (ML)</a>, but it&rsquo;s the other way around. Machine Learning is a subset of Artificial Intelligence.&nbsp;</b></p>\\r\\n\\r\\n<p><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Machine Learning is a technique, approach, or process for implementing Artificial Intelligence which involves parsing massive amounts of data, learning from that data, and making predictions based on that.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">What you should know about Machine Learning programs is that the more data you feed them, the better they get at making predictions. These Machine Learning algorithms modify on their own using the datasets.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Now comes the deepest(excuse the pun) part of Artificial Intelligence(AI) systems. Deep Learning is a subset of machine learning that involves the artificial neural network - the kind of neural network we have in our brains for making connections.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">You and many others might confuse Deep Learning with Machine Learning. But <a href=\"https://www.botreetechnologies.com/machine-learning-solutions\" target=\"_blank\">Deep Learning vs Machine Learnin</a>g is a much broader topic.&nbsp;</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Deep Learning algorithms are much more complex than simple Machine Learning algorithms. They make use of natural language processing combined with neural network development.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Neural networks are based on the biological neural networks that we have in our brains. It involves interconnecting different neurons(inputs in the case of Deep Learning) to form an output.</b></p>\\r\\n\\r\\n<p dir=\"ltr\"><b id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">This detailed blog at BoTree Technologies <a href=\"https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference\" target=\"_blank\">highlights the major differences between Machine Learning, </a></b><a href=\"https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference\" target=\"_blank\"><b>Deep Learning, and&nbsp;Artificial Intelligence</b></a><b>&nbsp;for your business.</b></p>\\r\\n',\n",
       "   'created_at': '2020-07-15T08:45:36.282Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/important-difference-between-machine-learning-vs-artificial-intelligence-vs-deep-learning',\n",
       "   'associated_topics': ['Deep Learning',\n",
       "    'Artificial Intelligence',\n",
       "    'Machine Learning'],\n",
       "   'post_links': [{'link_url': 'https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference'}]},\n",
       "  {'id': 6497,\n",
       "   'title': 'Difference Between a Nautical Mile and Statute Mile',\n",
       "   'content': '<p>A nautical mile is based on the circumference of the earth, and is equal to one minute of latitude. It is slightly more than a statute (land measured) mile (1 nautical mile = 1.1508 statute miles). Nautical miles are used for charting and navigating.</p>\\r\\n',\n",
       "   'created_at': '2020-07-10T21:02:37.114Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/difference-between-a-nautical-mile-and-statute-mile',\n",
       "   'associated_topics': ['Flight School'],\n",
       "   'post_links': []},\n",
       "  {'id': 6457,\n",
       "   'title': 'Algorithmic problems',\n",
       "   'content': 'Improve your skill of solving algorithmic problems \\r\\n \\r\\nhttps://codingzone.io/',\n",
       "   'created_at': '2020-07-08T16:42:02.536Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/algorithmic-problems',\n",
       "   'associated_topics': ['Coding'],\n",
       "   'post_links': []},\n",
       "  {'id': 6444,\n",
       "   'title': 'Difference Between a Course and a Heading',\n",
       "   'content': '<p>Heading (yaw) is used to describe the direction an object is pointing. In contrast, the course angle refers to the direction an object is actually moving.</p>\\r\\n',\n",
       "   'created_at': '2020-07-07T05:11:02.889Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/difference-between-a-course-and-a-heading',\n",
       "   'associated_topics': ['Ground School', 'Flight School', 'Private Pilot'],\n",
       "   'post_links': [{'link_url': 'http://www.chrobotics.com/library/heading-course-and-crab-angle#:~:text=Heading%20(yaw)%20is%20used%20to,an%20object%20is%20actually%20moving.&text=The%20difference%20between%20course%20and,%2C%20or%20side%2Dslip%20angle.'}]},\n",
       "  {'id': 6443,\n",
       "   'title': 'Top Drag and Drop Libraries for React Applications',\n",
       "   'content': '<p>When it comes to building out React JS applications, one of the more challenging (but also popular) features I&#39;m asked to build is the ability to drag and drop elements on a page.</p>\\r\\n\\r\\n<p>React has some great libraries for this exact feature and I wanted to list out the two ones that I use on a regular basis: React Beautiful DND and React Sortable HOC.</p>\\r\\n\\r\\n<p>Why do I use two libraries for the same drag and drop functionality? The reason is related to the type of page elements that I&#39;m working with.</p>\\r\\n\\r\\n<p>React Beautiful DND is probably the most popular components in the React ecosystem for building drag and drop features. It also has great documentation with plenty of examples that you can use in your codebase. It also works great when you&#39;re required to implement the ability to drag and drop between multiple types of lists (e.g. sites like Trello). It is also maintained by Atlassian, so it has solid support and is updated regularly.</p>\\r\\n\\r\\n<p>However, I&#39;ve ran into issues with React Beautiful DND when it comes to working with grid based data.</p>\\r\\n\\r\\n<p>For example, React Beautiful DND works great for dragging and dropping with lists like the one below:</p>\\r\\n\\r\\n<p><img alt=\"\" src=\"http://www.crondose.com/wp-content/uploads/2020/07/Snip20200706_10.png\" /></p>\\r\\n\\r\\n<p>However, for lists that use tools such as Flexbox, with dynamic layouts, React Beautiful DND can be challenging to work with. An example is below:</p>\\r\\n\\r\\n<p><img alt=\"\" src=\"http://www.crondose.com/wp-content/uploads/2020/07/Snip20200706_11.png\" /></p>\\r\\n\\r\\n<p>Thankfully, the React Sortable HOC works perfectly in this type of situation. The implementation for React Sortable HOC is a little more advanced than Beautiful DND, however, it gives you more control over the drag and drop&nbsp;process and can work with dynamic layouts such as required by image galleries. React Sortable HOC also has a great set of examples that you can follow in their documentation.</p>\\r\\n\\r\\n<p><em><strong>One rule of thumb I follow is to always wrap the list and item components up in a provider/context so that the data, API calls, and resorting can be managed explictly.</strong></em></p>\\r\\n\\r\\n<p>So if you&#39;re looking to build out drag and drop features in a React app, I definitely recommend checking out these libraries.</p>\\r\\n',\n",
       "   'created_at': '2020-07-07T01:25:04.566Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/top-drag-and-drop-libraries-for-react-applications',\n",
       "   'associated_topics': ['Drag and Drop', 'React JS', 'React'],\n",
       "   'post_links': [{'link_url': 'https://github.com/clauderic/react-sortable-hoc'},\n",
       "    {'link_url': 'https://github.com/atlassian/react-beautiful-dnd'}]},\n",
       "  {'id': 6438,\n",
       "   'title': 'When to Use CSS Browser Prefixes',\n",
       "   'content': '<p>It can be pretty tricky to remember which CSS rules need to have a prefix and which ones don&#39;t. This site gives a comprehensive breakdown on when you should use a CSS browser prefix.</p>\\r\\n',\n",
       "   'created_at': '2020-07-05T01:20:23.006Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/when-to-use-css-browser-prefixes',\n",
       "   'associated_topics': ['CSS'],\n",
       "   'post_links': [{'link_url': 'http://shouldiprefix.com/'}]},\n",
       "  {'id': 6431,\n",
       "   'title': 'Buy Discount  Wellbutrin SR from India |Wellbutrin SR shipped with no prescription ',\n",
       "   'content': 'Buy Discount  Wellbutrin SR in Canada  pay with mastercard,visa,ach,echeck ; I Want To Buy  Wellbutrin SR  in UK/GB shipped by cash on delivery  ; <b>Order At Low Cost  Wellbutrin SR from India  overnight without a prescription </b> ; Low Price  Wellbutrin SR in Australia  without rx  ; Purchase At Low Price  Wellbutrin SR in UK/GB  internet drugs overnight  \\r\\n \\r\\nENTER HERE! SAVE MONEY WITH US! >>>> https://bit.ly/usamedsonline  \\r\\n \\r\\n \\r\\nBuy Discount  Wellbutrin SR from India |Wellbutrin SR shipped with no prescription  \\r\\n \\r\\n<quote> \\r\\n*** Top Quality for brand and generic meds \\r\\n*** Low prices + Bonuses \\r\\n*** NO PRESCRIPTION REQUIRED \\r\\n*** Fast Worldwide Delivery! \\r\\n*** No Hidden Costs or Membership Fees! \\r\\n*** 24/7/365 Customer Support \\r\\n*** We accept: Visa/MasterCard/eCheck/Amex \\r\\n</quote> \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n<i><b>Buy Discount  Wellbutrin SR from India |Wellbutrin SR shipped with no prescription </b></i> \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\nRELATED TAGS: \\r\\n \\r\\ngeneric  Wellbutrin SR in Canada  \\r\\npurchase  Wellbutrin SR saturday USA  \\r\\nbuying cheap  Wellbutrin SR online overnight delivery USA  \\r\\n \\r\\n<b>Buy Discount  Wellbutrin SR from India |Wellbutrin SR shipped with no prescription </b> \\r\\n \\r\\ndiscount drugs  Wellbutrin SR online overnight delivery USA  \\r\\nWellbutrin SR online at low cost  \\r\\norder online cheap  Wellbutrin SR with free fedex overnight  \\r\\nWellbutrin SR in USA no prescription needed  \\r\\nordering  Wellbutrin SR saturday delivery USA  \\r\\nWellbutrin SR cash on delivery overnight  \\r\\npharmacy  Wellbutrin SR online with visa  \\r\\nWellbutrin SR same day delivery USA  \\r\\nsafe order for generic  Wellbutrin SR free overnight fedex delivery  \\r\\nWellbutrin SR legal fda dea approved  \\r\\nbuy cheap online  Wellbutrin SR prescription online  \\r\\nWellbutrin SR next day delivery  \\r\\ndiscount tablets  Wellbutrin SR tablets without script USA  \\r\\nWellbutrin SR same day delivery USA  \\r\\nlegit place to buying  Wellbutrin SR overnight shipping  \\r\\nWellbutrin SR cod saturday delivery USA  \\r\\npurchase cheap online  Wellbutrin SR online drugstore no prescription  \\r\\nWellbutrin SR online legally  \\r\\nhow can i get  Wellbutrin SR in argentina without prescription  \\r\\nWellbutrin SR no perscription overnight in Maryland ;buy online cheap  Wellbutrin SR overnight delivery no rx USA ;fda approved  Wellbutrin SR in Canada ;where to purchase  Wellbutrin SR from India  \\r\\nmail order discounts on  Wellbutrin SR USA no prescription ;tablets  Wellbutrin SR delivered next day  \\r\\nlow cost  Wellbutrin SR no prescription overnight shipping  \\r\\nlicensed pharmacy to buy  Wellbutrin SRin Baton Rouge  \\r\\nWellbutrin SR prescriptions online  \\r\\nbuy legitimate  Wellbutrin SRin Great Britain  \\r\\ncan i purchase generic  Wellbutrin SR without prescription  \\r\\nwhere can i buy  generic  Wellbutrin SR medication without rx  \\r\\nbest prices for  Wellbutrin SR in Canada ;order with low price  Wellbutrin SR online overnight shipping ;get at low cost  Wellbutrin SRin Australia ;order generic  Wellbutrin SR overnight delivery  \\r\\nbest price  Wellbutrin SR online overnight shipping ;discount price for  Wellbutrin SR no prior script overnight USA ;Wellbutrin SR no rx required USA  \\r\\nwhere do i get  Wellbutrin SR from India ;buy online cheap  Wellbutrin SRin New York ;where to get  Wellbutrin SR in UK/GB ;purchase cheapest generic  Wellbutrin SR nextday shipping ;order easy  Wellbutrin SR in Australia  \\r\\ngeneric  Wellbutrin SR in Australia  \\r\\nwhere can i buy  generic  Wellbutrin SR in Canada //order online cheap  Wellbutrin SR in Australia ;;generic  Wellbutrin SR in Canada ;buy at low price  Wellbutrin SR in USA ;cheap price for  generic  Wellbutrin SR in UK/GB  \\r\\norder safety  Wellbutrin SR in Canada ;low prices  Wellbutrin SR from India ;indian  Wellbutrin SR in Canada ;get approved  Wellbutrin SR in Australia ;where to get  Wellbutrin SR in UK/GB ; \\r\\npurchase at best price  Wellbutrin SR in USA  \\r\\nbuy online generic  Wellbutrin SR in Australia  \\r\\nbuy  easy  Wellbutrin SR in UK/GB  \\r\\n<a href=https://jatevesifoorumi.fi/viewtopic.php?f=12&t=125981&p=147938#p147938> get  Wellbutrin SR no prior script overnight   </a>  & <a href=http://primalguild.org/forum/showthread.php?tid=897951> pharmacy  Wellbutrin SR with no prescription   </a>  & <a href=https://jatevesifoorumi.fi/viewtopic.php?f=12&t=143604&p=175930#p175930> licensed pharmacy  Wellbutrin SR overnight delivery without a rx   </a>  & <a href=http://xclub2.pre.transsion.net/forum.php?mod=viewthread&tid=2969742&pid=11728857&page=1&extra=#pid11728857> purchase online  Wellbutrin SR online no prescription fedex   </a>  & <a href=http://fastfoodfanatics.com/showthread.php?tid=312782&pid=1651412#pid1651412> buy online generic  Wellbutrin SR tijuana   </a>  & <a href=http://sp-maniya.ru/forum/viewtopic.php?f=72&t=15357&p=47386#p47386> best prices for  Wellbutrin SR from a USA pharmacy without a prescription   </a>  & <a href=https://yuli10.com/forums/topic/buy-at-low-price-pyridium-in-usa-pyridium-tablet-without-script> how can i get  Wellbutrin SR online overnight shipping   </a>  & <a href=http://pokergid.net/forum/cat-sng-mtt/topic-354685-page-3.html#post586819> cheap generic  Wellbutrin SR without a prescription   </a>  & <a href=http://edullisethaat.fi/forums/topic/buy-online-ibuprofen-in-usa-ibuprofen-with-no-rx/> cheap buying online  Wellbutrin SR no prescription overnight shipping   </a>  & <a href=http://pionver.xyz/viewtopic.php?f=3&t=1316743&p=1415741#p1415741> where to buy  Wellbutrin SR cash on delivery   </a> \\r\\n',\n",
       "   'created_at': '2020-07-02T19:58:35.639Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/buy-discount-wellbutrin-sr-from-india-wellbutrin-sr-shipped-with-no-prescription',\n",
       "   'associated_topics': ['Tiny Care Terminal'],\n",
       "   'post_links': []},\n",
       "  {'id': 5947,\n",
       "   'title': 'Adding Google Fonts to React Native Expo IO Apps',\n",
       "   'content': '<p>The library below allows for integrating custom fonts from the Google font library into React Native apps that utilize the Expo.io framework.</p>\\r\\n',\n",
       "   'created_at': '2020-05-28T02:48:53.371Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/adding-google-fonts-to-react-native-expo-io-apps',\n",
       "   'associated_topics': ['Mobile Development', 'Fonts', 'React Native'],\n",
       "   'post_links': [{'link_url': 'https://dev.to/expo/expo-google-fonts-is-released-4g58'}]},\n",
       "  {'id': 5884,\n",
       "   'title': 'Web Spider/Crawler',\n",
       "   'content': '<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\"><span style=\"font-size:20.0pt\"><span style=\"line-height:107%\">Web Scraping using Scrapy and Python 3</span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Now I want to start off and talk a little about scraping. Web scraping has actually been around for a very long time, but certain companies like craigslist have filed a lot of lawsuits due to people stealing data or crashing servers constantly by scraping-which has made people go to using API&rsquo;s more. Now that does sound scary, especially when you hear the words lawsuit right? Well there are certain things you are able to do WITHOUT getting yourself into trouble and we will talk about a few of those today! </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">So, what is Web scraping, well the term usually used in the industry is web crawling or Spidering&hellip;but what does it all mean you ask? Well To put it simple it is literally just going over a collection of web pages and extracting the data. This is an extremely powerful tool when you are working with data on the web.&nbsp; With this tool you can get large amounts of data from mining certain products WITHOUT the use of an API!</span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">What we will be going over tonight will be learning the basic fundamentals of the scraping/spidering process and we are going to be using a site that deals with my daughters FAVORITE toys&hellip;.LEGOS!!!! We will be using a site called Brickset and we will be extracting the data in regard to HUNDREDS of LEGO sets, and displaying it to your screen!<br />\\r\\n<br />\\r\\nfor all of this to run properly you will need Python 3 installed and anaconda. Since most of you probably don&rsquo;t have anaconda installed I will need everyone to head over to this site<br />\\r\\n<a href=\"https://docs.anaconda.com/anaconda/install/\" style=\"color:blue; text-decoration:underline\">https://docs.anaconda.com/anaconda/install/</a><br />\\r\\nThis is called anaconda, I have been using this for YEARS now, you can run the program later and explore more but our main focus this evening is getting the anaconda installed and allowed to be open through VS code ( the steps are perfectly explained and simple) Once you have this installed close out your VS code and reopen it and we will then begin! </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\"><b>CREATING THE WEB CRAWLER</b></span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Now to begin you have to always remember how scraping works<br />\\r\\nfirst you have to build &ldquo;something&rdquo; that will be able to find and download the pages<br />\\r\\nand secondly you want to add to that build so you can then extract the information</span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">So now that we have that in mind lets start<br />\\r\\nScrapy is one of the most awesome and powerful Python crawling libraries in python. Think of it as more of the &ldquo;Batteries included&rdquo; approach of crawling(meaning it handles the main functionality for you so you as the developer do not have to keep rebuilding each time! It&rsquo;s actually a pretty straight forward process! Scrapy is located in the PyPi store <a href=\"https://pypi.org/\" style=\"color:blue; text-decoration:underline\">https://pypi.org/</a>&nbsp;&nbsp; a site if you didin&rsquo;t know that holds THOUSANDS of python packages on this community-owned repo! </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Now if you have python3 installed you will have pip installed which is going to what we use to install scrapy!</span></span></span></p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\"><span style=\"font-size:12pt\"><span style=\"background:white\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:black\">So lets go ahead and create the project directory( and if you are new to programing think of a directory as a folder on your desktop)</span></span></span></span><br />\\r\\n&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\"><span style=\"font-size:12pt\"><span style=\"background:white\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:black\">So open up your terminal in VS code by pressing ctrl+`&nbsp; (control+tilda)&nbsp; and if you are on windows run<br />\\r\\nmkdir legoset-scraper<br />\\r\\nnow run the command cd legoset-scraper&nbsp;&nbsp;&nbsp;&nbsp; (cd stands for change directory and then place the name of the directory we just made) and what this does is now places our whole environment in this directory! AWESOME RIGHT!!! Let&rsquo;s keep going<br />\\r\\n<br />\\r\\nInside of this directory at the top lets go ahead and create a file called scraper.py</span><br />\\r\\n<span style=\"color:#333333\">We&rsquo;ll start by making a very basic scraper that uses Scrapy as its foundation. To do that, we&rsquo;ll create a&nbsp;</span><span style=\"color:black\"><a href=\"https://www.digitalocean.com/community/tutorials/how-to-construct-classes-and-define-objects-in-python-3\" style=\"color:blue; text-decoration:underline\"><span style=\"color:black\"><span style=\"text-decoration:none\"><span style=\"text-underline:none\">Python class</span></span></span></a></span><span style=\"color:#333333\">&nbsp;that subclasses&nbsp;</span><span style=\"color:black\">scrapy.Spider,</span><span style=\"color:#333333\"> a basic spider class provided by Scrapy. This class will have two required attributes:</span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">name&nbsp;&mdash; just a name for the spider.<br />\\r\\nstart_urls&nbsp;&mdash; a&nbsp;<a href=\"https://www.digitalocean.com/community/tutorials/understanding-lists-in-python-3\" style=\"color:blue; text-decoration:underline\"><span style=\"color:black\">list</span></a>&nbsp;of URLs that you start to crawl from. (We will start with one URL.)<br />\\r\\n<span style=\"font-size:10.5pt\"><span style=\"line-height:107%\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">import scrapy</span></span></span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt 274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt 549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span style=\"font-family:Calibri,sans-serif\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">class BrickSetSpider(scrapy.Spider):</span></span></span></span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt 274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt 549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span style=\"font-family:Calibri,sans-serif\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp; name = &quot;brickset_spider&quot;</span></span></span></span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.8pt\"><span style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt 274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt 549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span style=\"font-family:Calibri,sans-serif\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp; start_urls = [&#39;http://brickset.com/sets/year-2020&#39;]</span></span></span></span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\"><span style=\"font-size:12pt\"><span style=\"background:white\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"background:white\"><span style=\"color:#333333\">Next, we take the&nbsp;</span></span><span style=\"color:black\">Spider</span><span style=\"background:white\"><span style=\"color:#333333\">&nbsp;class provided by Scrapy and make a&nbsp;<em><span style=\"font-style:normal\">subclass</span></em>&nbsp;out of it called&nbsp;</span></span><span style=\"color:black\">BrickSetSpider.</span><span style=\"background:white\"><span style=\"color:#333333\"> Think of a subclass as a more specialized form of its parent class. The&nbsp;</span></span><span style=\"color:black\">Spider&nbsp;subclass</span><span style=\"background:white\"><span style=\"color:#333333\"> has methods and behaviors that define how to follow URLs and extract data from the pages it finds, but it does not know where to look or what data to look for. By sub-classing it, we can give it that information. </span></span><span style=\"color:#333333\">Finally, we give our scraper a single URL to start from:&nbsp;</span><span style=\"color:black\"><a href=\"http://brickset.com/sets/year-2016\" style=\"color:blue; text-decoration:underline\"><span style=\"color:black\">http://brickset.com/sets/year-2016</span></a></span><span style=\"color:#333333\">. If you open that URL in your browser, it will take you to a search results page, showing the first of many pages containing LEGO sets. Now let&rsquo;s test out the scraper. You typically run Python files by running a command like&nbsp;</span><span style=\"color:black\">python path/to/file.py.</span><span style=\"color:#333333\"> However, Scrapy comes with&nbsp;</span><span style=\"color:black\"><a href=\"https://doc.scrapy.org/en/latest/topics/commands.html\" style=\"color:blue; text-decoration:underline\"><span style=\"color:black\"><span style=\"text-decoration:none\"><span style=\"text-underline:none\">its own command line interface</span></span></span></a></span><span style=\"color:#333333\">&nbsp;to streamline the process of starting a scraper. Start your scraper with the following command:<br />\\r\\nin your terminal now I want you to watch what I do at the end of the line start_urls press<br />\\r\\nshift+enter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----and what this will do is fire up anaconda in your terminal if it doesn&rsquo;t fire &nbsp;up then it&rsquo;s okay simply run the command<br />\\r\\npip install Scrapy -----this will go out and install the Scrapy library from the Pypi store now run<br />\\r\\nscrapy runspider scraper.py<br />\\r\\nThis is the output&hellip;&hellip;&hellip;&hellip;&hellip;.(show output)</span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\"><span style=\"font-size:12pt\"><span style=\"background:white\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:#333333\">So what happened here, so when we ran the scraper it loaded all the additional components and extensions it needed while reading all of the data from the site URL we provided<br />\\r\\nit then used that same link in the start_urls list, it made a digital copy of the HTML in the background (sort of how a web browser works) and then passed all of the HTML it copied to the parse method (which since a parse method was never created by us the spider literally finishes it without doing anything else!<br />\\r\\nNow that was okay but lets do one better, lets actually bring back the data from that site<br />\\r\\n<br />\\r\\nI will open the html src from the inspect tool and we will see some headers literally on every page we are looking at and then the search data including what we are matching to! And literally everything looks like an Ordered list!<br />\\r\\nSo we will need to now extract each set of data pertaining to the LEGO sets<br />\\r\\nand then for each LEGO set we want to pull the data down<br />\\r\\n<br />\\r\\nScrapy lets us grab all sorts of data based on selectors which are simple just the patters we use to find the elements on the page. We can use CSS selectors or XPath selectors. We will use CSS selectors. Since we are looking for a specific class we will use .set for our CSS selector and after that we will just pass that specific selector into the response object.</span></span></span></span><br />\\r\\n<br />\\r\\n&nbsp;</p>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">def parse(self, response):</span></span></span></code></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">SET_SELECTOR = &#39;.set&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">for brickset in response.css(SET_SELECTOR):</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.8pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code></span></span></span></span></pre>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\"><br />\\r\\n<span style=\"font-size:12pt\"><span style=\"background:white\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:#333333\"><span style=\"background:white\">This code grabs all the sets on the page and loops over them to extract the data. Now let us extract the data from those sets so we can display it. The&nbsp;</span></span><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"background:#f2f2f2\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:#545454\">brickset</span></span></span></code><span style=\"background:white\"><span style=\"color:#333333\">&nbsp;object we are looping over has its own&nbsp;</span></span><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"background:#f2f2f2\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:#545454\">css</span></span></span></code><span style=\"background:white\"><span style=\"color:#333333\">&nbsp;method, so we can pass in a selector to locate child elements. So now below the response lets type</span></span></span></span></span></p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NAME_SELECTOR = &#39;h1 ::text&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">yield {</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&#39;name&#39;: brickset.css(NAME_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.8pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">}</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n\\r\\n&nbsp;</pre>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Some things you might have questions about lets circle back to the code now, you will notice in our name selector that we have some weird code ::text&nbsp;&nbsp;&nbsp; what we are doing here is appending ::text to our selector (CSS pseudo-selector), and all it is doing is grabbing all of the text INSIDE the a tag instead of the tag itself</span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">And then the extract_first() is being called on the object brick_set.css line, because we want the first element that matched the selector which will return us a string instead of a bunch of elements we can&rsquo;t work with! </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Save the file and run<br />\\r\\nscrapy runspider scraper.py<br />\\r\\nAND LOOK AT THAT&hellip;. Notice the output has names now!<br />\\r\\n<br />\\r\\nNow I would like to now add new selectors for images, miniature figures or otherwise called minifigs that are coming with our set. The image for the set is stored in the&nbsp;src&nbsp;attribute of an&nbsp;img&nbsp;tag inside an&nbsp;a&nbsp;tag at the start of the set. We can use another CSS selector to fetch this value just like we did when we grabbed the name of each set. Getting the number of pieces is a little trickier. There&rsquo;s a&nbsp;dt&nbsp;tag that contains the text&nbsp;Pieces, and then a&nbsp;dd&nbsp;tag that follows it which contains the actual number of pieces. We&rsquo;ll use&nbsp;<a href=\"https://en.wikipedia.org/wiki/XPath\" style=\"color:blue; text-decoration:underline\"><span style=\"text-decoration:none\"><span style=\"text-underline:none\">XPath</span></span></a>, a query language for traversing XML, to grab this, because it&rsquo;s too complex to be represented using CSS selectors. Getting the number of minifigs in a set is like getting the number of pieces. There is a&nbsp;dt&nbsp;tag that contains the text&nbsp;Minifigs, followed by a&nbsp;dd&nbsp;tag right after that with the number.</span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  NAME_SELECTOR = &#39;h1 ::text&#39;</span></span></span></code></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">PIECES_SELECTOR = &#39;.//dl[dt/text() = &quot;Pieces&quot;]/dd/a/text()&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">MINIFIGS_SELECTOR = &#39;.//dl[dt/text() = &quot;Minifigs&quot;]/dd[2]/a/text()&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">IMAGE_SELECTOR = &#39;img ::attr(src)&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  yield {</span></span></span></code></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#39;name&#39;: brickset.css(NAME_SELECTOR).extract_first(),</span></span></span></code></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&#39;pieces&#39;: brickset.xpath(PIECES_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&#39;minifigs&#39;: brickset.xpath(MINIFIGS_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&#39;image&#39;: brickset.css(IMAGE_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.8pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></span></span></code></span></span></span></span></pre>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Press ctrl+s to save your work and lets run the scraper command once again and see what output we get<br />\\r\\nscrapy runspider scraper.py<br />\\r\\n<br />\\r\\nLook at the data now we are returning the name the image the minifigs WOW nice work everyone!<br />\\r\\nBUT WE AREN&rdquo;T DONE YET! </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\"><span style=\"font-size:11pt\"><span style=\"line-height:107%\"><span style=\"font-family:Calibri,sans-serif\">Now lets modify our scraper so that our spider can follow all the links!<br />\\r\\nThis is commonly called Crawling Multiple Pages and this is out last part<br />\\r\\n<br />\\r\\n<br />\\r\\nSo to break down what we have done so far we extracted all the data from the initial site, but what if we wanted to go to page 2 or 3 or 4 ?how would we do it? The whole point of the spider is to traverse through the links to the other pages and grab all of that data as well. If we go to the html you will notice that there is a greater than sign/arrow pointing right&nbsp; &gt;&nbsp;&nbsp;&nbsp;&nbsp; after every page, which gives us a hint on our last step. All we have to do now is tell it &ldquo;follow the link, and if it is going on to another page open that next page and continue extracting data&rdquo; </span></span></span></p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NEXT_PAGE_SELECTOR = &#39;.next a ::attr(href)&#39;</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">next_page = response.css(NEXT_PAGE_SELECTOR).extract_first()</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">if next_page:</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">yield scrapy.Request(</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">response.urljoin(next_page),</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.5pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">callback=self.parse</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n<span style=\"font-size:10pt\"><span style=\"background:#f2f2f2\"><span style=\"line-height:16.8pt\"><span style=\"font-family:&quot;Courier New&quot;\"><code style=\"font-family:&quot;Courier New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span style=\"font-size:10.5pt\"><span style=\"font-family:Consolas\"><span style=\"color:#545454\">)</span></span></span></span></span></span></span></pre>\\r\\n\\r\\n<p style=\"margin:0in 0in 8pt; margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p style=\"margin-top:0in; margin-right:0in; margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n\\r\\n<p><span style=\"font-size:11.0pt\"><span style=\"line-height:107%\"><span style=\"font-family:&quot;Calibri&quot;,sans-serif\">First, we define a selector for the &ldquo;next page&rdquo; link, extract the first match, and check if it exists. The&nbsp;scrapy.Request&nbsp;is a value that we return saying &ldquo;Hey, crawl this page&rdquo;, and&nbsp;callback=self.parse&nbsp;says &ldquo;once you&rsquo;ve gotten the HTML from this page, pass it back to this method so we can parse it, extract the data, and find the next page.&ldquo; This means that once we go to the next page, we&rsquo;ll look for a link to the next page there, and on that page we&rsquo;ll look for a link to the next page, and so on, until we don&rsquo;t find a link for the next page. This is the key piece of web scraping: finding and following links. In this example, it&rsquo;s very linear; one page has a link to the next page until we&rsquo;ve hit the last page, But you could follow links to tags, or other search results, or any other URL you&rsquo;d like. Now, if you save your code and run the spider again,<br />\\r\\nscrapy runspider scraper.py<br />\\r\\n<br />\\r\\nYou will see that it doesn&rsquo;t just stop once it iterates through the first page of sets. It keeps on going and In the grand scheme of things, it&rsquo;s not a huge chunk of data, but now you know the process by which you automatically find new pages to scrape.<br />\\r\\nNow last and final command lets run</span></span></span><br />\\r\\n<span style=\"font-size:12.0pt\"><span style=\"line-height:107%\"><span style=\"font-family:&quot;Times New Roman&quot;,serif\"><span style=\"color:#333333\">scrapy runspider scraper.py -o file.csv </span></span></span></span><br />\\r\\n<span style=\"font-size:11.0pt\"><span style=\"line-height:107%\"><span style=\"font-family:&quot;Calibri&quot;,sans-serif\">and what this will do is create a csv file inside of our directory than you can see all of the data that we just extracted from the site! Simply highlight and copy and paste one of the link images into your browser and notice it is correct and working!</span></span></span></p>\\r\\n',\n",
       "   'created_at': '2020-05-23T04:02:18.438Z',\n",
       "   'url_for_post': 'http://www.dailysmarty.com/posts/web-spider-crawler',\n",
       "   'associated_topics': [],\n",
       "   'post_links': []}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'posts': [{'associated_topics': ['Rails Migrations',\n",
      "                                  'Databases',\n",
      "                                  'Ruby on Rails'],\n",
      "            'content': '<p>The Ruby on Rails framework has some helpful '\n",
      "                       'shorthand methods for when you want to change the '\n",
      "                       'structure of your database. If you want to rename a '\n",
      "                       'column, you can create a migration with the terminal '\n",
      "                       'command:</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>rails g migration change_some_name</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>And then the code in the migration file should look '\n",
      "                       'something like this:</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>class ChangeSomeName &lt; '\n",
      "                       'ActiveRecord::Migration[6.0]<br />\\r\\n'\n",
      "                       '&nbsp; def change<br />\\r\\n'\n",
      "                       '&nbsp; &nbsp; rename_column :table_name, :old_name, '\n",
      "                       ':new_name<br />\\r\\n'\n",
      "                       '&nbsp; end<br />\\r\\n'\n",
      "                       'end</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>After you run: rails db:migrate, the new name will '\n",
      "                       'be updated in the database. A few things to keep in '\n",
      "                       'mind:</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<ul>\\r\\n'\n",
      "                       '\\t<li>Make sure to update any/all mentions of the old '\n",
      "                       'name in the: strong params, serializers, seed files, '\n",
      "                       'show templates, etc.</li>\\r\\n'\n",
      "                       '\\t<li>Ensure that the table name you&#39;re using '\n",
      "                       'matches the table name as it appears in the '\n",
      "                       'db/schema.rb file</li>\\r\\n'\n",
      "                       '</ul>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>For more information on rails migrations, the guide '\n",
      "                       'below is very helpful.</p>\\r\\n',\n",
      "            'created_at': '2020-07-29T01:34:31.773Z',\n",
      "            'id': 6822,\n",
      "            'post_links': [{'link_url': 'https://edgeguides.rubyonrails.org/active_record_migrations.html'}],\n",
      "            'title': 'How to Rename a Column in Ruby on Rails',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/how-to-rename-a-column-in-ruby-on-rails'},\n",
      "           {'associated_topics': ['Deep Learning',\n",
      "                                  'Artificial Intelligence',\n",
      "                                  'Machine Learning'],\n",
      "            'content': '<p><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Artificial '\n",
      "                       'Intelligence is the technique of developing machines '\n",
      "                       'that imitate human behaviour. It provides objects, '\n",
      "                       'machines, and systems the ability to simulate human '\n",
      "                       'behaviour.&nbsp;</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><meta charset=\"utf-8\" /></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Think '\n",
      "                       'of this way - Artificial Intelligence(AI) systems are '\n",
      "                       'machines that think and act as humans do. They have an '\n",
      "                       'intelligent brain, just like humans do.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">It '\n",
      "                       'is useful to your organization in ways you can&rsquo;t '\n",
      "                       'even imagine - an accurate visual perception of data, '\n",
      "                       'speech recognition, extracting insights from data, '\n",
      "                       'translation of documents and languages, and much '\n",
      "                       'more.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Machine '\n",
      "                       'Learning is the building blocks behind Artificial '\n",
      "                       'Intelligence systems. You might have read somewhere '\n",
      "                       'about AI and ML and probably gotten '\n",
      "                       'confused.&nbsp;</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">You '\n",
      "                       'may also think that <a '\n",
      "                       'href=\"https://www.botreetechnologies.com/artificial-intelligence-solutions\" '\n",
      "                       'target=\"_blank\">AI is a subset of Machine Learning '\n",
      "                       '(ML)</a>, but it&rsquo;s the other way around. Machine '\n",
      "                       'Learning is a subset of Artificial '\n",
      "                       'Intelligence.&nbsp;</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Machine '\n",
      "                       'Learning is a technique, approach, or process for '\n",
      "                       'implementing Artificial Intelligence which involves '\n",
      "                       'parsing massive amounts of data, learning from that '\n",
      "                       'data, and making predictions based on that.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">What '\n",
      "                       'you should know about Machine Learning programs is '\n",
      "                       'that the more data you feed them, the better they get '\n",
      "                       'at making predictions. These Machine Learning '\n",
      "                       'algorithms modify on their own using the '\n",
      "                       'datasets.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Now '\n",
      "                       'comes the deepest(excuse the pun) part of Artificial '\n",
      "                       'Intelligence(AI) systems. Deep Learning is a subset of '\n",
      "                       'machine learning that involves the artificial neural '\n",
      "                       'network - the kind of neural network we have in our '\n",
      "                       'brains for making connections.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">You '\n",
      "                       'and many others might confuse Deep Learning with '\n",
      "                       'Machine Learning. But <a '\n",
      "                       'href=\"https://www.botreetechnologies.com/machine-learning-solutions\" '\n",
      "                       'target=\"_blank\">Deep Learning vs Machine Learnin</a>g '\n",
      "                       'is a much broader topic.&nbsp;</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Deep '\n",
      "                       'Learning algorithms are much more complex than simple '\n",
      "                       'Machine Learning algorithms. They make use of natural '\n",
      "                       'language processing combined with neural network '\n",
      "                       'development.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">Neural '\n",
      "                       'networks are based on the biological neural networks '\n",
      "                       'that we have in our brains. It involves '\n",
      "                       'interconnecting different neurons(inputs in the case '\n",
      "                       'of Deep Learning) to form an output.</b></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p dir=\"ltr\"><b '\n",
      "                       'id=\"docs-internal-guid-cf5a4c7c-7fff-9f72-1b8a-31dce2dd55ea\">This '\n",
      "                       'detailed blog at BoTree Technologies <a '\n",
      "                       'href=\"https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference\" '\n",
      "                       'target=\"_blank\">highlights the major differences '\n",
      "                       'between Machine Learning, </a></b><a '\n",
      "                       'href=\"https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference\" '\n",
      "                       'target=\"_blank\"><b>Deep Learning, and&nbsp;Artificial '\n",
      "                       'Intelligence</b></a><b>&nbsp;for your '\n",
      "                       'business.</b></p>\\r\\n',\n",
      "            'created_at': '2020-07-15T08:45:36.282Z',\n",
      "            'id': 6591,\n",
      "            'post_links': [{'link_url': 'https://www.botreetechnologies.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-difference'}],\n",
      "            'title': 'Important Difference between Machine Learning vs '\n",
      "                     'Artificial Intelligence vs Deep Learning',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/important-difference-between-machine-learning-vs-artificial-intelligence-vs-deep-learning'},\n",
      "           {'associated_topics': ['Flight School'],\n",
      "            'content': '<p>A nautical mile is based on the circumference of '\n",
      "                       'the earth, and is equal to one minute of latitude. It '\n",
      "                       'is slightly more than a statute (land measured) mile '\n",
      "                       '(1 nautical mile = 1.1508 statute miles). Nautical '\n",
      "                       'miles are used for charting and navigating.</p>\\r\\n',\n",
      "            'created_at': '2020-07-10T21:02:37.114Z',\n",
      "            'id': 6497,\n",
      "            'post_links': [],\n",
      "            'title': 'Difference Between a Nautical Mile and Statute Mile',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/difference-between-a-nautical-mile-and-statute-mile'},\n",
      "           {'associated_topics': ['Coding'],\n",
      "            'content': 'Improve your skill of solving algorithmic problems \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'https://codingzone.io/',\n",
      "            'created_at': '2020-07-08T16:42:02.536Z',\n",
      "            'id': 6457,\n",
      "            'post_links': [],\n",
      "            'title': 'Algorithmic problems',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/algorithmic-problems'},\n",
      "           {'associated_topics': ['Ground School',\n",
      "                                  'Flight School',\n",
      "                                  'Private Pilot'],\n",
      "            'content': '<p>Heading (yaw) is used to describe the direction an '\n",
      "                       'object is pointing. In contrast, the course angle '\n",
      "                       'refers to the direction an object is actually '\n",
      "                       'moving.</p>\\r\\n',\n",
      "            'created_at': '2020-07-07T05:11:02.889Z',\n",
      "            'id': 6444,\n",
      "            'post_links': [{'link_url': 'http://www.chrobotics.com/library/heading-course-and-crab-angle#:~:text=Heading%20(yaw)%20is%20used%20to,an%20object%20is%20actually%20moving.&text=The%20difference%20between%20course%20and,%2C%20or%20side%2Dslip%20angle.'}],\n",
      "            'title': 'Difference Between a Course and a Heading',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/difference-between-a-course-and-a-heading'},\n",
      "           {'associated_topics': ['Drag and Drop', 'React JS', 'React'],\n",
      "            'content': '<p>When it comes to building out React JS '\n",
      "                       'applications, one of the more challenging (but also '\n",
      "                       'popular) features I&#39;m asked to build is the '\n",
      "                       'ability to drag and drop elements on a page.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>React has some great libraries for this exact '\n",
      "                       'feature and I wanted to list out the two ones that I '\n",
      "                       'use on a regular basis: React Beautiful DND and React '\n",
      "                       'Sortable HOC.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>Why do I use two libraries for the same drag and '\n",
      "                       'drop functionality? The reason is related to the type '\n",
      "                       'of page elements that I&#39;m working with.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>React Beautiful DND is probably the most popular '\n",
      "                       'components in the React ecosystem for building drag '\n",
      "                       'and drop features. It also has great documentation '\n",
      "                       'with plenty of examples that you can use in your '\n",
      "                       'codebase. It also works great when you&#39;re required '\n",
      "                       'to implement the ability to drag and drop between '\n",
      "                       'multiple types of lists (e.g. sites like Trello). It '\n",
      "                       'is also maintained by Atlassian, so it has solid '\n",
      "                       'support and is updated regularly.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>However, I&#39;ve ran into issues with React '\n",
      "                       'Beautiful DND when it comes to working with grid based '\n",
      "                       'data.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>For example, React Beautiful DND works great for '\n",
      "                       'dragging and dropping with lists like the one '\n",
      "                       'below:</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><img alt=\"\" '\n",
      "                       'src=\"http://www.crondose.com/wp-content/uploads/2020/07/Snip20200706_10.png\" '\n",
      "                       '/></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>However, for lists that use tools such as Flexbox, '\n",
      "                       'with dynamic layouts, React Beautiful DND can be '\n",
      "                       'challenging to work with. An example is below:</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><img alt=\"\" '\n",
      "                       'src=\"http://www.crondose.com/wp-content/uploads/2020/07/Snip20200706_11.png\" '\n",
      "                       '/></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>Thankfully, the React Sortable HOC works perfectly '\n",
      "                       'in this type of situation. The implementation for '\n",
      "                       'React Sortable HOC is a little more advanced than '\n",
      "                       'Beautiful DND, however, it gives you more control over '\n",
      "                       'the drag and drop&nbsp;process and can work with '\n",
      "                       'dynamic layouts such as required by image galleries. '\n",
      "                       'React Sortable HOC also has a great set of examples '\n",
      "                       'that you can follow in their documentation.</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><em><strong>One rule of thumb I follow is to always '\n",
      "                       'wrap the list and item components up in a '\n",
      "                       'provider/context so that the data, API calls, and '\n",
      "                       'resorting can be managed '\n",
      "                       'explictly.</strong></em></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p>So if you&#39;re looking to build out drag and drop '\n",
      "                       'features in a React app, I definitely recommend '\n",
      "                       'checking out these libraries.</p>\\r\\n',\n",
      "            'created_at': '2020-07-07T01:25:04.566Z',\n",
      "            'id': 6443,\n",
      "            'post_links': [{'link_url': 'https://github.com/clauderic/react-sortable-hoc'},\n",
      "                           {'link_url': 'https://github.com/atlassian/react-beautiful-dnd'}],\n",
      "            'title': 'Top Drag and Drop Libraries for React Applications',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/top-drag-and-drop-libraries-for-react-applications'},\n",
      "           {'associated_topics': ['CSS'],\n",
      "            'content': '<p>It can be pretty tricky to remember which CSS rules '\n",
      "                       'need to have a prefix and which ones don&#39;t. This '\n",
      "                       'site gives a comprehensive breakdown on when you '\n",
      "                       'should use a CSS browser prefix.</p>\\r\\n',\n",
      "            'created_at': '2020-07-05T01:20:23.006Z',\n",
      "            'id': 6438,\n",
      "            'post_links': [{'link_url': 'http://shouldiprefix.com/'}],\n",
      "            'title': 'When to Use CSS Browser Prefixes',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/when-to-use-css-browser-prefixes'},\n",
      "           {'associated_topics': ['Tiny Care Terminal'],\n",
      "            'content': 'Buy Discount  Wellbutrin SR in Canada  pay with '\n",
      "                       'mastercard,visa,ach,echeck ; I Want To Buy  Wellbutrin '\n",
      "                       'SR  in UK/GB shipped by cash on delivery  ; <b>Order '\n",
      "                       'At Low Cost  Wellbutrin SR from India  overnight '\n",
      "                       'without a prescription </b> ; Low Price  Wellbutrin SR '\n",
      "                       'in Australia  without rx  ; Purchase At Low Price  '\n",
      "                       'Wellbutrin SR in UK/GB  internet drugs overnight  \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'ENTER HERE! SAVE MONEY WITH US! >>>> '\n",
      "                       'https://bit.ly/usamedsonline  \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'Buy Discount  Wellbutrin SR from India |Wellbutrin SR '\n",
      "                       'shipped with no prescription  \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       '<quote> \\r\\n'\n",
      "                       '*** Top Quality for brand and generic meds \\r\\n'\n",
      "                       '*** Low prices + Bonuses \\r\\n'\n",
      "                       '*** NO PRESCRIPTION REQUIRED \\r\\n'\n",
      "                       '*** Fast Worldwide Delivery! \\r\\n'\n",
      "                       '*** No Hidden Costs or Membership Fees! \\r\\n'\n",
      "                       '*** 24/7/365 Customer Support \\r\\n'\n",
      "                       '*** We accept: Visa/MasterCard/eCheck/Amex \\r\\n'\n",
      "                       '</quote> \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       '<i><b>Buy Discount  Wellbutrin SR from India '\n",
      "                       '|Wellbutrin SR shipped with no prescription '\n",
      "                       '</b></i> \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'RELATED TAGS: \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'generic  Wellbutrin SR in Canada  \\r\\n'\n",
      "                       'purchase  Wellbutrin SR saturday USA  \\r\\n'\n",
      "                       'buying cheap  Wellbutrin SR online overnight delivery '\n",
      "                       'USA  \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       '<b>Buy Discount  Wellbutrin SR from India |Wellbutrin '\n",
      "                       'SR shipped with no prescription </b> \\r\\n'\n",
      "                       ' \\r\\n'\n",
      "                       'discount drugs  Wellbutrin SR online overnight '\n",
      "                       'delivery USA  \\r\\n'\n",
      "                       'Wellbutrin SR online at low cost  \\r\\n'\n",
      "                       'order online cheap  Wellbutrin SR with free fedex '\n",
      "                       'overnight  \\r\\n'\n",
      "                       'Wellbutrin SR in USA no prescription needed  \\r\\n'\n",
      "                       'ordering  Wellbutrin SR saturday delivery USA  \\r\\n'\n",
      "                       'Wellbutrin SR cash on delivery overnight  \\r\\n'\n",
      "                       'pharmacy  Wellbutrin SR online with visa  \\r\\n'\n",
      "                       'Wellbutrin SR same day delivery USA  \\r\\n'\n",
      "                       'safe order for generic  Wellbutrin SR free overnight '\n",
      "                       'fedex delivery  \\r\\n'\n",
      "                       'Wellbutrin SR legal fda dea approved  \\r\\n'\n",
      "                       'buy cheap online  Wellbutrin SR prescription '\n",
      "                       'online  \\r\\n'\n",
      "                       'Wellbutrin SR next day delivery  \\r\\n'\n",
      "                       'discount tablets  Wellbutrin SR tablets without script '\n",
      "                       'USA  \\r\\n'\n",
      "                       'Wellbutrin SR same day delivery USA  \\r\\n'\n",
      "                       'legit place to buying  Wellbutrin SR overnight '\n",
      "                       'shipping  \\r\\n'\n",
      "                       'Wellbutrin SR cod saturday delivery USA  \\r\\n'\n",
      "                       'purchase cheap online  Wellbutrin SR online drugstore '\n",
      "                       'no prescription  \\r\\n'\n",
      "                       'Wellbutrin SR online legally  \\r\\n'\n",
      "                       'how can i get  Wellbutrin SR in argentina without '\n",
      "                       'prescription  \\r\\n'\n",
      "                       'Wellbutrin SR no perscription overnight in Maryland '\n",
      "                       ';buy online cheap  Wellbutrin SR overnight delivery no '\n",
      "                       'rx USA ;fda approved  Wellbutrin SR in Canada ;where '\n",
      "                       'to purchase  Wellbutrin SR from India  \\r\\n'\n",
      "                       'mail order discounts on  Wellbutrin SR USA no '\n",
      "                       'prescription ;tablets  Wellbutrin SR delivered next '\n",
      "                       'day  \\r\\n'\n",
      "                       'low cost  Wellbutrin SR no prescription overnight '\n",
      "                       'shipping  \\r\\n'\n",
      "                       'licensed pharmacy to buy  Wellbutrin SRin Baton '\n",
      "                       'Rouge  \\r\\n'\n",
      "                       'Wellbutrin SR prescriptions online  \\r\\n'\n",
      "                       'buy legitimate  Wellbutrin SRin Great Britain  \\r\\n'\n",
      "                       'can i purchase generic  Wellbutrin SR without '\n",
      "                       'prescription  \\r\\n'\n",
      "                       'where can i buy  generic  Wellbutrin SR medication '\n",
      "                       'without rx  \\r\\n'\n",
      "                       'best prices for  Wellbutrin SR in Canada ;order with '\n",
      "                       'low price  Wellbutrin SR online overnight shipping '\n",
      "                       ';get at low cost  Wellbutrin SRin Australia ;order '\n",
      "                       'generic  Wellbutrin SR overnight delivery  \\r\\n'\n",
      "                       'best price  Wellbutrin SR online overnight shipping '\n",
      "                       ';discount price for  Wellbutrin SR no prior script '\n",
      "                       'overnight USA ;Wellbutrin SR no rx required USA  \\r\\n'\n",
      "                       'where do i get  Wellbutrin SR from India ;buy online '\n",
      "                       'cheap  Wellbutrin SRin New York ;where to get  '\n",
      "                       'Wellbutrin SR in UK/GB ;purchase cheapest generic  '\n",
      "                       'Wellbutrin SR nextday shipping ;order easy  Wellbutrin '\n",
      "                       'SR in Australia  \\r\\n'\n",
      "                       'generic  Wellbutrin SR in Australia  \\r\\n'\n",
      "                       'where can i buy  generic  Wellbutrin SR in Canada '\n",
      "                       '//order online cheap  Wellbutrin SR in Australia '\n",
      "                       ';;generic  Wellbutrin SR in Canada ;buy at low price  '\n",
      "                       'Wellbutrin SR in USA ;cheap price for  generic  '\n",
      "                       'Wellbutrin SR in UK/GB  \\r\\n'\n",
      "                       'order safety  Wellbutrin SR in Canada ;low prices  '\n",
      "                       'Wellbutrin SR from India ;indian  Wellbutrin SR in '\n",
      "                       'Canada ;get approved  Wellbutrin SR in Australia '\n",
      "                       ';where to get  Wellbutrin SR in UK/GB ; \\r\\n'\n",
      "                       'purchase at best price  Wellbutrin SR in USA  \\r\\n'\n",
      "                       'buy online generic  Wellbutrin SR in Australia  \\r\\n'\n",
      "                       'buy  easy  Wellbutrin SR in UK/GB  \\r\\n'\n",
      "                       '<a '\n",
      "                       'href=https://jatevesifoorumi.fi/viewtopic.php?f=12&t=125981&p=147938#p147938> '\n",
      "                       'get  Wellbutrin SR no prior script overnight   </a>  & '\n",
      "                       '<a '\n",
      "                       'href=http://primalguild.org/forum/showthread.php?tid=897951> '\n",
      "                       'pharmacy  Wellbutrin SR with no prescription   </a>  & '\n",
      "                       '<a '\n",
      "                       'href=https://jatevesifoorumi.fi/viewtopic.php?f=12&t=143604&p=175930#p175930> '\n",
      "                       'licensed pharmacy  Wellbutrin SR overnight delivery '\n",
      "                       'without a rx   </a>  & <a '\n",
      "                       'href=http://xclub2.pre.transsion.net/forum.php?mod=viewthread&tid=2969742&pid=11728857&page=1&extra=#pid11728857> '\n",
      "                       'purchase online  Wellbutrin SR online no prescription '\n",
      "                       'fedex   </a>  & <a '\n",
      "                       'href=http://fastfoodfanatics.com/showthread.php?tid=312782&pid=1651412#pid1651412> '\n",
      "                       'buy online generic  Wellbutrin SR tijuana   </a>  & <a '\n",
      "                       'href=http://sp-maniya.ru/forum/viewtopic.php?f=72&t=15357&p=47386#p47386> '\n",
      "                       'best prices for  Wellbutrin SR from a USA pharmacy '\n",
      "                       'without a prescription   </a>  & <a '\n",
      "                       'href=https://yuli10.com/forums/topic/buy-at-low-price-pyridium-in-usa-pyridium-tablet-without-script> '\n",
      "                       'how can i get  Wellbutrin SR online overnight '\n",
      "                       'shipping   </a>  & <a '\n",
      "                       'href=http://pokergid.net/forum/cat-sng-mtt/topic-354685-page-3.html#post586819> '\n",
      "                       'cheap generic  Wellbutrin SR without a prescription   '\n",
      "                       '</a>  & <a '\n",
      "                       'href=http://edullisethaat.fi/forums/topic/buy-online-ibuprofen-in-usa-ibuprofen-with-no-rx/> '\n",
      "                       'cheap buying online  Wellbutrin SR no prescription '\n",
      "                       'overnight shipping   </a>  & <a '\n",
      "                       'href=http://pionver.xyz/viewtopic.php?f=3&t=1316743&p=1415741#p1415741> '\n",
      "                       'where to buy  Wellbutrin SR cash on delivery   '\n",
      "                       '</a> \\r\\n',\n",
      "            'created_at': '2020-07-02T19:58:35.639Z',\n",
      "            'id': 6431,\n",
      "            'post_links': [],\n",
      "            'title': 'Buy Discount  Wellbutrin SR from India |Wellbutrin SR '\n",
      "                     'shipped with no prescription ',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/buy-discount-wellbutrin-sr-from-india-wellbutrin-sr-shipped-with-no-prescription'},\n",
      "           {'associated_topics': ['Mobile Development',\n",
      "                                  'Fonts',\n",
      "                                  'React Native'],\n",
      "            'content': '<p>The library below allows for integrating custom '\n",
      "                       'fonts from the Google font library into React Native '\n",
      "                       'apps that utilize the Expo.io framework.</p>\\r\\n',\n",
      "            'created_at': '2020-05-28T02:48:53.371Z',\n",
      "            'id': 5947,\n",
      "            'post_links': [{'link_url': 'https://dev.to/expo/expo-google-fonts-is-released-4g58'}],\n",
      "            'title': 'Adding Google Fonts to React Native Expo IO Apps',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/adding-google-fonts-to-react-native-expo-io-apps'},\n",
      "           {'associated_topics': [],\n",
      "            'content': '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\"><span '\n",
      "                       'style=\"font-size:20.0pt\"><span '\n",
      "                       'style=\"line-height:107%\">Web Scraping using Scrapy and '\n",
      "                       'Python 3</span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Now I want to '\n",
      "                       'start off and talk a little about scraping. Web '\n",
      "                       'scraping has actually been around for a very long '\n",
      "                       'time, but certain companies like craigslist have filed '\n",
      "                       'a lot of lawsuits due to people stealing data or '\n",
      "                       'crashing servers constantly by scraping-which has made '\n",
      "                       'people go to using API&rsquo;s more. Now that does '\n",
      "                       'sound scary, especially when you hear the words '\n",
      "                       'lawsuit right? Well there are certain things you are '\n",
      "                       'able to do WITHOUT getting yourself into trouble and '\n",
      "                       'we will talk about a few of those today! '\n",
      "                       '</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">So, what is Web '\n",
      "                       'scraping, well the term usually used in the industry '\n",
      "                       'is web crawling or Spidering&hellip;but what does it '\n",
      "                       'all mean you ask? Well To put it simple it is '\n",
      "                       'literally just going over a collection of web pages '\n",
      "                       'and extracting the data. This is an extremely powerful '\n",
      "                       'tool when you are working with data on the web.&nbsp; '\n",
      "                       'With this tool you can get large amounts of data from '\n",
      "                       'mining certain products WITHOUT the use of an '\n",
      "                       'API!</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">What we will be '\n",
      "                       'going over tonight will be learning the basic '\n",
      "                       'fundamentals of the scraping/spidering process and we '\n",
      "                       'are going to be using a site that deals with my '\n",
      "                       'daughters FAVORITE toys&hellip;.LEGOS!!!! We will be '\n",
      "                       'using a site called Brickset and we will be extracting '\n",
      "                       'the data in regard to HUNDREDS of LEGO sets, and '\n",
      "                       'displaying it to your screen!<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'for all of this to run properly you will need Python 3 '\n",
      "                       'installed and anaconda. Since most of you probably '\n",
      "                       'don&rsquo;t have anaconda installed I will need '\n",
      "                       'everyone to head over to this site<br />\\r\\n'\n",
      "                       '<a href=\"https://docs.anaconda.com/anaconda/install/\" '\n",
      "                       'style=\"color:blue; '\n",
      "                       'text-decoration:underline\">https://docs.anaconda.com/anaconda/install/</a><br '\n",
      "                       '/>\\r\\n'\n",
      "                       'This is called anaconda, I have been using this for '\n",
      "                       'YEARS now, you can run the program later and explore '\n",
      "                       'more but our main focus this evening is getting the '\n",
      "                       'anaconda installed and allowed to be open through VS '\n",
      "                       'code ( the steps are perfectly explained and simple) '\n",
      "                       'Once you have this installed close out your VS code '\n",
      "                       'and reopen it and we will then begin! '\n",
      "                       '</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\"><b>CREATING THE '\n",
      "                       'WEB CRAWLER</b></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Now to begin '\n",
      "                       'you have to always remember how scraping works<br '\n",
      "                       '/>\\r\\n'\n",
      "                       'first you have to build &ldquo;something&rdquo; that '\n",
      "                       'will be able to find and download the pages<br />\\r\\n'\n",
      "                       'and secondly you want to add to that build so you can '\n",
      "                       'then extract the '\n",
      "                       'information</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">So now that we '\n",
      "                       'have that in mind lets start<br />\\r\\n'\n",
      "                       'Scrapy is one of the most awesome and powerful Python '\n",
      "                       'crawling libraries in python. Think of it as more of '\n",
      "                       'the &ldquo;Batteries included&rdquo; approach of '\n",
      "                       'crawling(meaning it handles the main functionality for '\n",
      "                       'you so you as the developer do not have to keep '\n",
      "                       'rebuilding each time! It&rsquo;s actually a pretty '\n",
      "                       'straight forward process! Scrapy is located in the '\n",
      "                       'PyPi store <a href=\"https://pypi.org/\" '\n",
      "                       'style=\"color:blue; '\n",
      "                       'text-decoration:underline\">https://pypi.org/</a>&nbsp;&nbsp; '\n",
      "                       'a site if you didin&rsquo;t know that holds THOUSANDS '\n",
      "                       'of python packages on this community-owned repo! '\n",
      "                       '</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Now if you have '\n",
      "                       'python3 installed you will have pip installed which is '\n",
      "                       'going to what we use to install '\n",
      "                       'scrapy!</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:12pt\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span style=\"color:black\">So lets '\n",
      "                       'go ahead and create the project directory( and if you '\n",
      "                       'are new to programing think of a directory as a folder '\n",
      "                       'on your desktop)</span></span></span></span><br />\\r\\n'\n",
      "                       '&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:12pt\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span style=\"color:black\">So open '\n",
      "                       'up your terminal in VS code by pressing ctrl+`&nbsp; '\n",
      "                       '(control+tilda)&nbsp; and if you are on windows run<br '\n",
      "                       '/>\\r\\n'\n",
      "                       'mkdir legoset-scraper<br />\\r\\n'\n",
      "                       'now run the command cd '\n",
      "                       'legoset-scraper&nbsp;&nbsp;&nbsp;&nbsp; (cd stands for '\n",
      "                       'change directory and then place the name of the '\n",
      "                       'directory we just made) and what this does is now '\n",
      "                       'places our whole environment in this directory! '\n",
      "                       'AWESOME RIGHT!!! Let&rsquo;s keep going<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'Inside of this directory at the top lets go ahead and '\n",
      "                       'create a file called scraper.py</span><br />\\r\\n'\n",
      "                       '<span style=\"color:#333333\">We&rsquo;ll start by '\n",
      "                       'making a very basic scraper that uses Scrapy as its '\n",
      "                       'foundation. To do that, we&rsquo;ll create '\n",
      "                       'a&nbsp;</span><span style=\"color:black\"><a '\n",
      "                       'href=\"https://www.digitalocean.com/community/tutorials/how-to-construct-classes-and-define-objects-in-python-3\" '\n",
      "                       'style=\"color:blue; text-decoration:underline\"><span '\n",
      "                       'style=\"color:black\"><span '\n",
      "                       'style=\"text-decoration:none\"><span '\n",
      "                       'style=\"text-underline:none\">Python '\n",
      "                       'class</span></span></span></a></span><span '\n",
      "                       'style=\"color:#333333\">&nbsp;that '\n",
      "                       'subclasses&nbsp;</span><span '\n",
      "                       'style=\"color:black\">scrapy.Spider,</span><span '\n",
      "                       'style=\"color:#333333\"> a basic spider class provided '\n",
      "                       'by Scrapy. This class will have two required '\n",
      "                       'attributes:</span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">name&nbsp;&mdash; '\n",
      "                       'just a name for the spider.<br />\\r\\n'\n",
      "                       'start_urls&nbsp;&mdash; a&nbsp;<a '\n",
      "                       'href=\"https://www.digitalocean.com/community/tutorials/understanding-lists-in-python-3\" '\n",
      "                       'style=\"color:blue; text-decoration:underline\"><span '\n",
      "                       'style=\"color:black\">list</span></a>&nbsp;of URLs that '\n",
      "                       'you start to crawl from. (We will start with one '\n",
      "                       'URL.)<br />\\r\\n'\n",
      "                       '<span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">import '\n",
      "                       'scrapy</span></span></span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; '\n",
      "                       'margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; '\n",
      "                       'margin-right:0in; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; '\n",
      "                       'margin-right:0in; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:11pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt '\n",
      "                       '274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt '\n",
      "                       '549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">class '\n",
      "                       'BrickSetSpider(scrapy.Spider):</span></span></span></span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; '\n",
      "                       'margin-right:0in; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:11pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt '\n",
      "                       '274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt '\n",
      "                       '549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp; name = '\n",
      "                       '&quot;brickset_spider&quot;</span></span></span></span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-bottom:.0001pt; margin:0in 0in 8pt; '\n",
      "                       'margin-right:0in; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:11pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.8pt\"><span '\n",
      "                       'style=\"tab-stops:45.8pt 91.6pt 137.4pt 183.2pt 229.0pt '\n",
      "                       '274.8pt 320.6pt 366.4pt 412.2pt 458.0pt 503.8pt '\n",
      "                       '549.6pt 595.4pt 641.2pt 687.0pt 732.8pt\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp; start_urls = '\n",
      "                       '[&#39;http://brickset.com/sets/year-2020&#39;]</span></span></span></span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:12pt\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"color:#333333\">Next, we take '\n",
      "                       'the&nbsp;</span></span><span '\n",
      "                       'style=\"color:black\">Spider</span><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"color:#333333\">&nbsp;class provided by Scrapy '\n",
      "                       'and make a&nbsp;<em><span '\n",
      "                       'style=\"font-style:normal\">subclass</span></em>&nbsp;out '\n",
      "                       'of it called&nbsp;</span></span><span '\n",
      "                       'style=\"color:black\">BrickSetSpider.</span><span '\n",
      "                       'style=\"background:white\"><span style=\"color:#333333\"> '\n",
      "                       'Think of a subclass as a more specialized form of its '\n",
      "                       'parent class. The&nbsp;</span></span><span '\n",
      "                       'style=\"color:black\">Spider&nbsp;subclass</span><span '\n",
      "                       'style=\"background:white\"><span style=\"color:#333333\"> '\n",
      "                       'has methods and behaviors that define how to follow '\n",
      "                       'URLs and extract data from the pages it finds, but it '\n",
      "                       'does not know where to look or what data to look for. '\n",
      "                       'By sub-classing it, we can give it that information. '\n",
      "                       '</span></span><span style=\"color:#333333\">Finally, we '\n",
      "                       'give our scraper a single URL to start '\n",
      "                       'from:&nbsp;</span><span style=\"color:black\"><a '\n",
      "                       'href=\"http://brickset.com/sets/year-2016\" '\n",
      "                       'style=\"color:blue; text-decoration:underline\"><span '\n",
      "                       'style=\"color:black\">http://brickset.com/sets/year-2016</span></a></span><span '\n",
      "                       'style=\"color:#333333\">. If you open that URL in your '\n",
      "                       'browser, it will take you to a search results page, '\n",
      "                       'showing the first of many pages containing LEGO sets. '\n",
      "                       'Now let&rsquo;s test out the scraper. You typically '\n",
      "                       'run Python files by running a command '\n",
      "                       'like&nbsp;</span><span style=\"color:black\">python '\n",
      "                       'path/to/file.py.</span><span style=\"color:#333333\"> '\n",
      "                       'However, Scrapy comes with&nbsp;</span><span '\n",
      "                       'style=\"color:black\"><a '\n",
      "                       'href=\"https://doc.scrapy.org/en/latest/topics/commands.html\" '\n",
      "                       'style=\"color:blue; text-decoration:underline\"><span '\n",
      "                       'style=\"color:black\"><span '\n",
      "                       'style=\"text-decoration:none\"><span '\n",
      "                       'style=\"text-underline:none\">its own command line '\n",
      "                       'interface</span></span></span></a></span><span '\n",
      "                       'style=\"color:#333333\">&nbsp;to streamline the process '\n",
      "                       'of starting a scraper. Start your scraper with the '\n",
      "                       'following command:<br />\\r\\n'\n",
      "                       'in your terminal now I want you to watch what I do at '\n",
      "                       'the end of the line start_urls press<br />\\r\\n'\n",
      "                       'shift+enter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '-----and what this will do is fire up anaconda in your '\n",
      "                       'terminal if it doesn&rsquo;t fire &nbsp;up then '\n",
      "                       'it&rsquo;s okay simply run the command<br />\\r\\n'\n",
      "                       'pip install Scrapy -----this will go out and install '\n",
      "                       'the Scrapy library from the Pypi store now run<br '\n",
      "                       '/>\\r\\n'\n",
      "                       'scrapy runspider scraper.py<br />\\r\\n'\n",
      "                       'This is the '\n",
      "                       'output&hellip;&hellip;&hellip;&hellip;&hellip;.(show '\n",
      "                       'output)</span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\"><span '\n",
      "                       'style=\"font-size:12pt\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span style=\"color:#333333\">So what '\n",
      "                       'happened here, so when we ran the scraper it loaded '\n",
      "                       'all the additional components and extensions it needed '\n",
      "                       'while reading all of the data from the site URL we '\n",
      "                       'provided<br />\\r\\n'\n",
      "                       'it then used that same link in the start_urls list, it '\n",
      "                       'made a digital copy of the HTML in the background '\n",
      "                       '(sort of how a web browser works) and then passed all '\n",
      "                       'of the HTML it copied to the parse method (which since '\n",
      "                       'a parse method was never created by us the spider '\n",
      "                       'literally finishes it without doing anything else!<br '\n",
      "                       '/>\\r\\n'\n",
      "                       'Now that was okay but lets do one better, lets '\n",
      "                       'actually bring back the data from that site<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'I will open the html src from the inspect tool and we '\n",
      "                       'will see some headers literally on every page we are '\n",
      "                       'looking at and then the search data including what we '\n",
      "                       'are matching to! And literally everything looks like '\n",
      "                       'an Ordered list!<br />\\r\\n'\n",
      "                       'So we will need to now extract each set of data '\n",
      "                       'pertaining to the LEGO sets<br />\\r\\n'\n",
      "                       'and then for each LEGO set we want to pull the data '\n",
      "                       'down<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'Scrapy lets us grab all sorts of data based on '\n",
      "                       'selectors which are simple just the patters we use to '\n",
      "                       'find the elements on the page. We can use CSS '\n",
      "                       'selectors or XPath selectors. We will use CSS '\n",
      "                       'selectors. Since we are looking for a specific class '\n",
      "                       'we will use .set for our CSS selector and after that '\n",
      "                       'we will just pass that specific selector into the '\n",
      "                       'response object.</span></span></span></span><br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       '&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">def parse(self, '\n",
      "                       'response):</span></span></span></code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">SET_SELECTOR = '\n",
      "                       '&#39;.set&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">for brickset in '\n",
      "                       'response.css(SET_SELECTOR):</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.8pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\"><br />\\r\\n'\n",
      "                       '<span style=\"font-size:12pt\"><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span style=\"color:#333333\"><span '\n",
      "                       'style=\"background:white\">This code grabs all the sets '\n",
      "                       'on the page and loops over them to extract the data. '\n",
      "                       'Now let us extract the data from those sets so we can '\n",
      "                       'display it. The&nbsp;</span></span><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span '\n",
      "                       'style=\"color:#545454\">brickset</span></span></span></code><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"color:#333333\">&nbsp;object we are looping over '\n",
      "                       'has its own&nbsp;</span></span><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span '\n",
      "                       'style=\"color:#545454\">css</span></span></span></code><span '\n",
      "                       'style=\"background:white\"><span '\n",
      "                       'style=\"color:#333333\">&nbsp;method, so we can pass in '\n",
      "                       'a selector to locate child elements. So now below the '\n",
      "                       'response lets '\n",
      "                       'type</span></span></span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       'NAME_SELECTOR = &#39;h1 '\n",
      "                       '::text&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">yield '\n",
      "                       '{</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&#39;name&#39;: '\n",
      "                       'brickset.css(NAME_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.8pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">}</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '&nbsp;</pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Some things you '\n",
      "                       'might have questions about lets circle back to the '\n",
      "                       'code now, you will notice in our name selector that we '\n",
      "                       'have some weird code ::text&nbsp;&nbsp;&nbsp; what we '\n",
      "                       'are doing here is appending ::text to our selector '\n",
      "                       '(CSS pseudo-selector), and all it is doing is grabbing '\n",
      "                       'all of the text INSIDE the a tag instead of the tag '\n",
      "                       'itself</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">And then the '\n",
      "                       'extract_first() is being called on the object '\n",
      "                       'brick_set.css line, because we want the first element '\n",
      "                       'that matched the selector which will return us a '\n",
      "                       'string instead of a bunch of elements we can&rsquo;t '\n",
      "                       'work with! </span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Save the file '\n",
      "                       'and run<br />\\r\\n'\n",
      "                       'scrapy runspider scraper.py<br />\\r\\n'\n",
      "                       'AND LOOK AT THAT&hellip;. Notice the output has names '\n",
      "                       'now!<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'Now I would like to now add new selectors for images, '\n",
      "                       'miniature figures or otherwise called minifigs that '\n",
      "                       'are coming with our set. The image for the set is '\n",
      "                       'stored in the&nbsp;src&nbsp;attribute of '\n",
      "                       'an&nbsp;img&nbsp;tag inside an&nbsp;a&nbsp;tag at the '\n",
      "                       'start of the set. We can use another CSS selector to '\n",
      "                       'fetch this value just like we did when we grabbed the '\n",
      "                       'name of each set. Getting the number of pieces is a '\n",
      "                       'little trickier. There&rsquo;s a&nbsp;dt&nbsp;tag that '\n",
      "                       'contains the text&nbsp;Pieces, and then '\n",
      "                       'a&nbsp;dd&nbsp;tag that follows it which contains the '\n",
      "                       'actual number of pieces. We&rsquo;ll use&nbsp;<a '\n",
      "                       'href=\"https://en.wikipedia.org/wiki/XPath\" '\n",
      "                       'style=\"color:blue; text-decoration:underline\"><span '\n",
      "                       'style=\"text-decoration:none\"><span '\n",
      "                       'style=\"text-underline:none\">XPath</span></span></a>, a '\n",
      "                       'query language for traversing XML, to grab this, '\n",
      "                       'because it&rsquo;s too complex to be represented using '\n",
      "                       'CSS selectors. Getting the number of minifigs in a set '\n",
      "                       'is like getting the number of pieces. There is '\n",
      "                       'a&nbsp;dt&nbsp;tag that contains the '\n",
      "                       'text&nbsp;Minifigs, followed by a&nbsp;dd&nbsp;tag '\n",
      "                       'right after that with the '\n",
      "                       'number.</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  '\n",
      "                       'NAME_SELECTOR = &#39;h1 '\n",
      "                       '::text&#39;</span></span></span></code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">PIECES_SELECTOR = '\n",
      "                       '&#39;.//dl[dt/text() = '\n",
      "                       '&quot;Pieces&quot;]/dd/a/text()&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">MINIFIGS_SELECTOR = '\n",
      "                       '&#39;.//dl[dt/text() = '\n",
      "                       '&quot;Minifigs&quot;]/dd[2]/a/text()&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">IMAGE_SELECTOR = &#39;img '\n",
      "                       '::attr(src)&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  '\n",
      "                       'yield '\n",
      "                       '{</span></span></span></code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '&#39;name&#39;: '\n",
      "                       'brickset.css(NAME_SELECTOR).extract_first(),</span></span></span></code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&#39;pieces&#39;: '\n",
      "                       'brickset.xpath(PIECES_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&#39;minifigs&#39;: '\n",
      "                       'brickset.xpath(MINIFIGS_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&#39;image&#39;: '\n",
      "                       'brickset.css(IMAGE_SELECTOR).extract_first(),</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.8pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '}</span></span></span></code></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Press ctrl+s to '\n",
      "                       'save your work and lets run the scraper command once '\n",
      "                       'again and see what output we get<br />\\r\\n'\n",
      "                       'scrapy runspider scraper.py<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'Look at the data now we are returning the name the '\n",
      "                       'image the minifigs WOW nice work everyone!<br />\\r\\n'\n",
      "                       'BUT WE AREN&rdquo;T DONE YET! '\n",
      "                       '</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\"><span style=\"font-size:11pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:Calibri,sans-serif\">Now lets modify '\n",
      "                       'our scraper so that our spider can follow all the '\n",
      "                       'links!<br />\\r\\n'\n",
      "                       'This is commonly called Crawling Multiple Pages and '\n",
      "                       'this is out last part<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'So to break down what we have done so far we extracted '\n",
      "                       'all the data from the initial site, but what if we '\n",
      "                       'wanted to go to page 2 or 3 or 4 ?how would we do it? '\n",
      "                       'The whole point of the spider is to traverse through '\n",
      "                       'the links to the other pages and grab all of that data '\n",
      "                       'as well. If we go to the html you will notice that '\n",
      "                       'there is a greater than sign/arrow pointing '\n",
      "                       'right&nbsp; &gt;&nbsp;&nbsp;&nbsp;&nbsp; after every '\n",
      "                       'page, which gives us a hint on our last step. All we '\n",
      "                       'have to do now is tell it &ldquo;follow the link, and '\n",
      "                       'if it is going on to another page open that next page '\n",
      "                       'and continue extracting data&rdquo; '\n",
      "                       '</span></span></span></p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       'NEXT_PAGE_SELECTOR = &#39;.next a '\n",
      "                       '::attr(href)&#39;</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">next_page = '\n",
      "                       'response.css(NEXT_PAGE_SELECTOR).extract_first()</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">if '\n",
      "                       'next_page:</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">yield '\n",
      "                       'scrapy.Request(</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">response.urljoin(next_page),</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.5pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '</code><span style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">callback=self.parse</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<pre style=\"margin:0in 0in 0.0001pt\">\\r\\n'\n",
      "                       '<span style=\"font-size:10pt\"><span '\n",
      "                       'style=\"background:#f2f2f2\"><span '\n",
      "                       'style=\"line-height:16.8pt\"><span '\n",
      "                       'style=\"font-family:&quot;Courier New&quot;\"><code '\n",
      "                       'style=\"font-family:&quot;Courier '\n",
      "                       'New&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '\n",
      "                       '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><span '\n",
      "                       'style=\"font-size:10.5pt\"><span '\n",
      "                       'style=\"font-family:Consolas\"><span '\n",
      "                       'style=\"color:#545454\">)</span></span></span></span></span></span></span></pre>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin:0in 0in 8pt; margin-right:0in; '\n",
      "                       'margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p style=\"margin-top:0in; margin-right:0in; '\n",
      "                       'margin-bottom:16.5pt; margin-left:0in\">&nbsp;</p>\\r\\n'\n",
      "                       '\\r\\n'\n",
      "                       '<p><span style=\"font-size:11.0pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:&quot;Calibri&quot;,sans-serif\">First, '\n",
      "                       'we define a selector for the &ldquo;next page&rdquo; '\n",
      "                       'link, extract the first match, and check if it exists. '\n",
      "                       'The&nbsp;scrapy.Request&nbsp;is a value that we return '\n",
      "                       'saying &ldquo;Hey, crawl this page&rdquo;, '\n",
      "                       'and&nbsp;callback=self.parse&nbsp;says &ldquo;once '\n",
      "                       'you&rsquo;ve gotten the HTML from this page, pass it '\n",
      "                       'back to this method so we can parse it, extract the '\n",
      "                       'data, and find the next page.&ldquo; This means that '\n",
      "                       'once we go to the next page, we&rsquo;ll look for a '\n",
      "                       'link to the next page there, and on that page '\n",
      "                       'we&rsquo;ll look for a link to the next page, and so '\n",
      "                       'on, until we don&rsquo;t find a link for the next '\n",
      "                       'page. This is the key piece of web scraping: finding '\n",
      "                       'and following links. In this example, it&rsquo;s very '\n",
      "                       'linear; one page has a link to the next page until '\n",
      "                       'we&rsquo;ve hit the last page, But you could follow '\n",
      "                       'links to tags, or other search results, or any other '\n",
      "                       'URL you&rsquo;d like. Now, if you save your code and '\n",
      "                       'run the spider again,<br />\\r\\n'\n",
      "                       'scrapy runspider scraper.py<br />\\r\\n'\n",
      "                       '<br />\\r\\n'\n",
      "                       'You will see that it doesn&rsquo;t just stop once it '\n",
      "                       'iterates through the first page of sets. It keeps on '\n",
      "                       'going and In the grand scheme of things, it&rsquo;s '\n",
      "                       'not a huge chunk of data, but now you know the process '\n",
      "                       'by which you automatically find new pages to '\n",
      "                       'scrape.<br />\\r\\n'\n",
      "                       'Now last and final command lets '\n",
      "                       'run</span></span></span><br />\\r\\n'\n",
      "                       '<span style=\"font-size:12.0pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:&quot;Times New '\n",
      "                       'Roman&quot;,serif\"><span style=\"color:#333333\">scrapy '\n",
      "                       'runspider scraper.py -o file.csv '\n",
      "                       '</span></span></span></span><br />\\r\\n'\n",
      "                       '<span style=\"font-size:11.0pt\"><span '\n",
      "                       'style=\"line-height:107%\"><span '\n",
      "                       'style=\"font-family:&quot;Calibri&quot;,sans-serif\">and '\n",
      "                       'what this will do is create a csv file inside of our '\n",
      "                       'directory than you can see all of the data that we '\n",
      "                       'just extracted from the site! Simply highlight and '\n",
      "                       'copy and paste one of the link images into your '\n",
      "                       'browser and notice it is correct and '\n",
      "                       'working!</span></span></span></p>\\r\\n',\n",
      "            'created_at': '2020-05-23T04:02:18.438Z',\n",
      "            'id': 5884,\n",
      "            'post_links': [],\n",
      "            'title': 'Web Spider/Crawler',\n",
      "            'url_for_post': 'http://www.dailysmarty.com/posts/web-spider-crawler'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'associated_topics': ['Rails Migrations', 'Databases', 'Ruby on Rails'],\n",
      " 'content': '<p>The Ruby on Rails framework has some helpful shorthand methods '\n",
      "            'for when you want to change the structure of your database. If '\n",
      "            'you want to rename a column, you can create a migration with the '\n",
      "            'terminal command:</p>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<p>rails g migration change_some_name</p>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<p>And then the code in the migration file should look something '\n",
      "            'like this:</p>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<p>class ChangeSomeName &lt; ActiveRecord::Migration[6.0]<br '\n",
      "            '/>\\r\\n'\n",
      "            '&nbsp; def change<br />\\r\\n'\n",
      "            '&nbsp; &nbsp; rename_column :table_name, :old_name, :new_name<br '\n",
      "            '/>\\r\\n'\n",
      "            '&nbsp; end<br />\\r\\n'\n",
      "            'end</p>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<p>After you run: rails db:migrate, the new name will be updated '\n",
      "            'in the database. A few things to keep in mind:</p>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<ul>\\r\\n'\n",
      "            '\\t<li>Make sure to update any/all mentions of the old name in '\n",
      "            'the: strong params, serializers, seed files, show templates, '\n",
      "            'etc.</li>\\r\\n'\n",
      "            '\\t<li>Ensure that the table name you&#39;re using matches the '\n",
      "            'table name as it appears in the db/schema.rb file</li>\\r\\n'\n",
      "            '</ul>\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '<p>For more information on rails migrations, the guide below is '\n",
      "            'very helpful.</p>\\r\\n',\n",
      " 'created_at': '2020-07-29T01:34:31.773Z',\n",
      " 'id': 6822,\n",
      " 'post_links': [{'link_url': 'https://edgeguides.rubyonrails.org/active_record_migrations.html'}],\n",
      " 'title': 'How to Rename a Column in Ruby on Rails',\n",
      " 'url_for_post': 'http://www.dailysmarty.com/posts/how-to-rename-a-column-in-ruby-on-rails'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(r.json()['posts'][0]) #the first post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2020-07-29T01:34:31.773Z'\n"
     ]
    }
   ],
   "source": [
    "# date of creation of post\n",
    "pprint.pprint(r.json()['posts'][0]['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.dailysmarty.com/posts/how-to-rename-a-column-in-ruby-on-rails'\n",
      "'How to Rename a Column in Ruby on Rails'\n"
     ]
    }
   ],
   "source": [
    "#url for accessing the post and the title of the post\n",
    "pprint.pprint(r.json()['posts'][0]['url_for_post'])\n",
    "pprint.pprint(r.json()['posts'][0]['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
